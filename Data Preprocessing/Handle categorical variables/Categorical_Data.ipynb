{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical variables\n",
    "\n",
    "## What is a categorical variable?\n",
    "\n",
    "In layman's terms, a quantity that is not a number but rather is a string or something of that sort is a categorical variable.\n",
    "\n",
    "## Why do we need to encode the categorical variables?\n",
    "\n",
    "Usually in machine learning, the data fed to the model or the results calculated are numeric. \n",
    "\n",
    "For example, say we want to predict a crop for a farmer to grow. Let the inputs be ambient temperature, average rainfall and soil type (red, black, loamy, sandy) in his farm land. The output would be the name of a crop.\n",
    "\n",
    "A problem arises.\n",
    "\n",
    "Not all inputs are in numeric format. The soil types are of string type. Neither is the output numeric.\n",
    "\n",
    "One way would be to assign numeric values to the soil types. Say 'red' = 0, 'black' = 1, 'loamy' = 2, 'sandy' = 3, or something of this type. This is called Label Encoding.\n",
    "\n",
    "Label Encoding has a huge flaw. The model would give more weightage to 'sandy' as compared to 'red' as the numeric value associated with 'sandy' is greater than that of 'red'.\n",
    "\n",
    "Hence we need to encode the variables in a different manner.\n",
    "\n",
    "## How do we encode the variables?\n",
    "\n",
    "There are various methods provided in python to do so.\n",
    "1. Ordinal\n",
    "2. OneHot (Most commonly used)\n",
    "3. Binary\n",
    "4. BaseN\n",
    "5. Hashing\n",
    "6. Sum\n",
    "7. Helmert\n",
    "8. Backward Difference\n",
    "9. Polynomial\n",
    "10. Target\n",
    "11. LeaveOneOut\n",
    "\n",
    "#### As OneHotEncoder has very high usage, we would be considering that.\n",
    "\n",
    "## OneHotEncoder\n",
    "\n",
    "Though label encoding is straight but it has the disadvantage that the numeric values can be misinterpreted by algorithms as having some sort of hierarchy/order in them. This ordering issue is addressed in another common alternative approach called ‘One-Hot Encoding’. In this strategy, each category value is converted into a new column and assigned a 1 or 0 (notation for true/false) value to the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = pd.read_csv('Crime_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              MSA ViolentCrime  Murder  Rape  \\\n",
      "0                              Abilene, TX M.S.A.        412.5     5.3  56.0   \n",
      "1                                Akron, OH M.S.A.        238.4     5.1  38.2   \n",
      "2                               Albany, GA M.S.A.        667.9     7.8  30.4   \n",
      "3                               Albany, OR M.S.A.        114.3     2.5  28.2   \n",
      "4                          Albuquerque, NM M.S.A.        792.6     6.1  63.8   \n",
      "..                                            ...          ...     ...   ...   \n",
      "373                   Guayama, Puerto Rico M.S.A.        251.6    11.4   6.3   \n",
      "374                  Mayaguez, Puerto Rico M.S.A.        237.5    11.5   5.2   \n",
      "375                     Ponce, Puerto Rico M.S.A.        231.4    18.0   5.0   \n",
      "376                San German, Puerto Rico M.S.A.         92.1     5.4   4.6   \n",
      "377  San Juan-Carolina-Caguas, Puerto Rico M.S.A.        262.0    20.6   4.9   \n",
      "\n",
      "     Robbery  AggravatedAssault PropertyCrime Burglary    Theft  \\\n",
      "0       78.4              272.8       3,609.0    852.0  2,493.6   \n",
      "1       75.2              119.8       2,552.4    575.3  1,853.0   \n",
      "2      157.9              471.8       3,894.1  1,099.6  2,652.8   \n",
      "3       20.7               63.0       3,208.4    484.6  2,476.1   \n",
      "4      206.7              516.0       4,607.8    883.4  3,047.6   \n",
      "..       ...                ...           ...      ...      ...   \n",
      "373     74.6              159.3         823.2    265.5    531.1   \n",
      "374     82.3              138.6       1,320.0    377.1    861.6   \n",
      "375     66.2              142.2         885.0    214.4    632.4   \n",
      "376     16.1               66.0         420.0    168.9    226.5   \n",
      "377    157.8               78.7       1,281.2    281.8    835.0   \n",
      "\n",
      "     MotorVehicleTheft                                         State  \\\n",
      "0                263.4                                            TX   \n",
      "1                124.1                                            OH   \n",
      "2                141.7                                            GA   \n",
      "3                247.7                                            OR   \n",
      "4                676.9                                            NM   \n",
      "..                 ...                                           ...   \n",
      "373               26.6                   Guayama, Puerto Rico M.S.A.   \n",
      "374               81.3                  Mayaguez, Puerto Rico M.S.A.   \n",
      "375               38.1                     Ponce, Puerto Rico M.S.A.   \n",
      "376               24.6                San German, Puerto Rico M.S.A.   \n",
      "377              164.3  San Juan-Carolina-Caguas, Puerto Rico M.S.A.   \n",
      "\n",
      "            City  \n",
      "0        Abilene  \n",
      "1          Akron  \n",
      "2         Albany  \n",
      "3         Albany  \n",
      "4    Albuquerque  \n",
      "..           ...  \n",
      "373      Guayama  \n",
      "374     Mayaguez  \n",
      "375        Ponce  \n",
      "376   San German  \n",
      "377     San Juan  \n",
      "\n",
      "[378 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(crime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data contains categorical variables in the form of cities.\n",
    "\n",
    "Here, we will try to encode the data of the states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding\n",
    "\n",
    "We import OneHotEncoder library from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an object of OneHotEncoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OneHotEncoder(categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')\n",
    "\n",
    "params:\n",
    "1. categories (unique values per feature): \n",
    "    'auto'(default): determine categories automatically from training data\n",
    "    'list'\n",
    "    \n",
    "2. drop (specifies a methodology to use to drop one of the categories per feature)\n",
    "    'none' (default): retain all features\n",
    "    'first': drop first category in each feature\n",
    "    drop[i] (array): ith column should be dropped\n",
    "    \n",
    "3. sparse: will return sparse matrix if set true, else array\n",
    "\n",
    "4. dtype: desired dtype of output\n",
    "    np.float (default)\n",
    "    \n",
    "5. handle_unknown: whether to raise an error or ignore if an unknown categorical feature is present during transform \n",
    "    'error' (default): raise error\n",
    "    'ignore': unknown category column would be set to zeros\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(categories = 'auto', drop = None, sparse = True, dtype = np.float, handle_unknown = 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "fit_transform(self, X, y = None)\n",
    "\n",
    "params:\n",
    "X: array-like, the data to encode\n",
    "y: None(default)\n",
    "returns a sparse matrix if sparse = True, else a 2-d array.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Here we have type casted the sparse matrix to a DataFrame.\n",
    "\"\"\"\n",
    "enc_df = pd.DataFrame(enc.fit_transform(crime_data[['State']]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1    2    3    4    5    6    7    8    9   ...   48   49   50  \\\n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "373  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
      "\n",
      "      51   52   53   54   55   56   57  \n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "373  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "374  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "375  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "376  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "377  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[378 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "print(enc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The steps now are to see how the data has been encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.DataFrame(crime_data['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = states_df.join(enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>OR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>Guayama, Puerto Rico M.S.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>Mayaguez, Puerto Rico M.S.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>Ponce, Puerto Rico M.S.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>San German, Puerto Rico M.S.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>San Juan-Carolina-Caguas, Puerto Rico M.S.A.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            State    0    1    2    3    4  \\\n",
       "0                                              TX  0.0  0.0  0.0  0.0  0.0   \n",
       "1                                              OH  0.0  0.0  0.0  0.0  0.0   \n",
       "2                                              GA  0.0  0.0  0.0  0.0  0.0   \n",
       "3                                              OR  0.0  0.0  0.0  0.0  0.0   \n",
       "4                                              NM  0.0  0.0  0.0  0.0  0.0   \n",
       "..                                            ...  ...  ...  ...  ...  ...   \n",
       "373                   Guayama, Puerto Rico M.S.A.  0.0  0.0  0.0  0.0  0.0   \n",
       "374                  Mayaguez, Puerto Rico M.S.A.  0.0  0.0  0.0  0.0  0.0   \n",
       "375                     Ponce, Puerto Rico M.S.A.  0.0  0.0  0.0  0.0  0.0   \n",
       "376                San German, Puerto Rico M.S.A.  0.0  0.0  0.0  0.0  0.0   \n",
       "377  San Juan-Carolina-Caguas, Puerto Rico M.S.A.  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       5    6    7    8  ...   48   49   50   51   52   53   54   55   56   57  \n",
       "0    0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "373  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "374  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "375  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "376  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "377  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[378 rows x 59 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy variables approach\n",
    "\n",
    "We can also use dummy variables to encode. This approach is more flexible as we can encode any number of columns and choose how to label the columns using a prefix. Proper naming makes the data analysis process easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to encode the names of famous cricketers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names of cricketers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sachin Tendulkar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Virat Kohli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MS Dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rahul Dravid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VVS Laxman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Names of cricketers\n",
       "0    Sachin Tendulkar\n",
       "1         Virat Kohli\n",
       "2            MS Dhoni\n",
       "3        Rahul Dravid\n",
       "4          VVS Laxman"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ('Sachin Tendulkar', 'Virat Kohli', 'MS Dhoni', 'Rahul Dravid', 'VVS Laxman')\n",
    "\n",
    "names_df = pd.DataFrame(names, columns = ['Names of cricketers'])\n",
    "\n",
    "names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_dummies(data, prefix = None, prefix_sep = '_', dummy_na = False, columns = None, sparse = False, drop_first = False, \n",
    "            dtype = None)\n",
    "            \n",
    "params:\n",
    "data: Data of which we want to get dummy indicators.\n",
    "      array-like, Series, or DataFrame\n",
    "prefix: String to append DataFrame column names.\n",
    "        Pass a list with length equal to column names.\n",
    "prefix_sep: default '_'. used while appending a prefix.\n",
    "dummy_na: Add a column to indicate NaNs, if false NaN's ignored.\n",
    "columns: column names in df to be encoded\n",
    "drop_first: Whether to remove first categorical level\n",
    "dtype: Data type for new colums.\n",
    "\n",
    "returns: DataFrame object\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dummy_df = pd.get_dummies(names_df, columns = [\"Names of cricketers\"], prefix = [\"Type_is\"], prefix_sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names of cricketers</th>\n",
       "      <th>Type_is MS Dhoni</th>\n",
       "      <th>Type_is Rahul Dravid</th>\n",
       "      <th>Type_is Sachin Tendulkar</th>\n",
       "      <th>Type_is VVS Laxman</th>\n",
       "      <th>Type_is Virat Kohli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sachin Tendulkar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MS Dhoni</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rahul Dravid</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VVS Laxman</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Names of cricketers  Type_is MS Dhoni  Type_is Rahul Dravid  \\\n",
       "0    Sachin Tendulkar                 0                     0   \n",
       "1         Virat Kohli                 0                     0   \n",
       "2            MS Dhoni                 1                     0   \n",
       "3        Rahul Dravid                 0                     1   \n",
       "4          VVS Laxman                 0                     0   \n",
       "\n",
       "   Type_is Sachin Tendulkar  Type_is VVS Laxman  Type_is Virat Kohli  \n",
       "0                         1                   0                    0  \n",
       "1                         0                   0                    1  \n",
       "2                         0                   0                    0  \n",
       "3                         0                   0                    0  \n",
       "4                         0                   1                    0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df = names_df.join(dummy_df)\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "As categorical variables are encountered frequently in Data Science, I think that this notebook will help you to understand them in a better way, and also how to encode them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
