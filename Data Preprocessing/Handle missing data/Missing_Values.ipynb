{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas to get dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using read_csv\n",
    "data = pd.read_csv(\"AirQualityUCI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Date  Time  CO(GT)  PT08.S1(CO)  \\\n",
      "10/03/2004 18.00.00 2.0 6.0    1360.0  150.0  11.0     9.0       1046.0   \n",
      "           19.00.00 2.0 1292.0 112.0     9.0   4.0   955.0        103.0   \n",
      "           20.00.00 2.0 2.0    1402.0   88.0   9.0     0.0        939.0   \n",
      "           21.00.00 2.0 2.0    1376.0   80.0   9.0     2.0        948.0   \n",
      "           22.00.00 1.0 6.0    1272.0   51.0   6.0     5.0        836.0   \n",
      "...                                      ...   ...     ...          ...   \n",
      "NaN        NaN      NaN NaN    NaN       NaN   NaN     NaN          NaN   \n",
      "                               NaN       NaN   NaN     NaN          NaN   \n",
      "                               NaN       NaN   NaN     NaN          NaN   \n",
      "                               NaN       NaN   NaN     NaN          NaN   \n",
      "                               NaN       NaN   NaN     NaN          NaN   \n",
      "\n",
      "                                       NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  \\\n",
      "10/03/2004 18.00.00 2.0 6.0    1360.0     166.0    1056.0          113.0   \n",
      "           19.00.00 2.0 1292.0 112.0     1174.0      92.0         1559.0   \n",
      "           20.00.00 2.0 2.0    1402.0     131.0    1140.0          114.0   \n",
      "           21.00.00 2.0 2.0    1376.0     172.0    1092.0          122.0   \n",
      "           22.00.00 1.0 6.0    1272.0     131.0    1205.0          116.0   \n",
      "...                                         ...       ...            ...   \n",
      "NaN        NaN      NaN NaN    NaN          NaN       NaN            NaN   \n",
      "                               NaN          NaN       NaN            NaN   \n",
      "                               NaN          NaN       NaN            NaN   \n",
      "                               NaN          NaN       NaN            NaN   \n",
      "                               NaN          NaN       NaN            NaN   \n",
      "\n",
      "                                       NOx(GT)  PT08.S3(NOx)  NO2(GT)  \\\n",
      "10/03/2004 18.00.00 2.0 6.0    1360.0   1692.0        1268.0     13.0   \n",
      "           19.00.00 2.0 1292.0 112.0     972.0          13.0      3.0   \n",
      "           20.00.00 2.0 2.0    1402.0   1555.0        1074.0     11.0   \n",
      "           21.00.00 2.0 2.0    1376.0   1584.0        1203.0     11.0   \n",
      "           22.00.00 1.0 6.0    1272.0   1490.0        1110.0     11.0   \n",
      "...                                        ...           ...      ...   \n",
      "NaN        NaN      NaN NaN    NaN         NaN           NaN      NaN   \n",
      "                               NaN         NaN           NaN      NaN   \n",
      "                               NaN         NaN           NaN      NaN   \n",
      "                               NaN         NaN           NaN      NaN   \n",
      "                               NaN         NaN           NaN      NaN   \n",
      "\n",
      "                                       PT08.S4(NO2)  PT08.S5(O3)    T      RH  \\\n",
      "10/03/2004 18.00.00 2.0 6.0    1360.0           6.0         48.0  9.0     0.0   \n",
      "           19.00.00 2.0 1292.0 112.0           47.0          7.0  0.0  7255.0   \n",
      "           20.00.00 2.0 2.0    1402.0           9.0         54.0  0.0     0.0   \n",
      "           21.00.00 2.0 2.0    1376.0           0.0         60.0  0.0     0.0   \n",
      "           22.00.00 1.0 6.0    1272.0           2.0         59.0  6.0     0.0   \n",
      "...                                             ...          ...  ...     ...   \n",
      "NaN        NaN      NaN NaN    NaN              NaN          NaN  NaN     NaN   \n",
      "                               NaN              NaN          NaN  NaN     NaN   \n",
      "                               NaN              NaN          NaN  NaN     NaN   \n",
      "                               NaN              NaN          NaN  NaN     NaN   \n",
      "                               NaN              NaN          NaN  NaN     NaN   \n",
      "\n",
      "                                           AH  Unnamed: 15  Unnamed: 16  \n",
      "10/03/2004 18.00.00 2.0 6.0    1360.0  7578.0          NaN          NaN  \n",
      "           19.00.00 2.0 1292.0 112.0      NaN          NaN          NaN  \n",
      "           20.00.00 2.0 2.0    1402.0  7502.0          NaN          NaN  \n",
      "           21.00.00 2.0 2.0    1376.0  7867.0          NaN          NaN  \n",
      "           22.00.00 1.0 6.0    1272.0  7888.0          NaN          NaN  \n",
      "...                                       ...          ...          ...  \n",
      "NaN        NaN      NaN NaN    NaN        NaN          NaN          NaN  \n",
      "                               NaN        NaN          NaN          NaN  \n",
      "                               NaN        NaN          NaN          NaN  \n",
      "                               NaN        NaN          NaN          NaN  \n",
      "                               NaN        NaN          NaN          NaN  \n",
      "\n",
      "[9471 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# printing data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 3 variables to consider replacing np.nan with mean, median, and mode\n",
    "\n",
    "data_mean = data\n",
    "data_median = data\n",
    "data_mode = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Imputer library from sklearn.preprocessing to take care of missing data\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object of imputer class which calculates mean of the column values to replace the NaN values\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "1. missing_values: int or NaN(default)\n",
    "2. strategy: mean(default), median, most_frequent (ie mode)\n",
    "3. axis: 0(default)(impute along columns) 1(impute along rows)\n",
    "4. verbose: 0(default) [verbose inshort tells the logging info. ref: https://stats.stackexchange.com/questions/153823/what-is-verbose-in-scikit-learn-package-of-python]\n",
    "5. copy: True(default)(copy of x created)\n",
    "\"\"\"\n",
    "\n",
    "imputer_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean',  verbose = 0, copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fit the imputer on the data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "data_mean.iloc[:, 2:16] as to select all rows and the columns from 2 to 15\n",
    "\"\"\"\n",
    "\n",
    "imputer_mean = imputer_mean.fit(data_mean.iloc[:, 2:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 14 features per sample, expected 13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-327b4cde0fd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimputer_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             raise ValueError(\"X has %d features per sample, expected %d\"\n\u001b[1;32m--> 384\u001b[1;33m                              % (X.shape[1], self.statistics_.shape[0]))\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_indicator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 14 features per sample, expected 13"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "impute all missing values in the dataset\n",
    "\"\"\"\n",
    "\n",
    "data_mean.iloc[:, 2:16] = imputer_mean.transform(data_mean.iloc[:, 2:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
